{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNXYzp6lFcS2oghL/rrhhln"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["###The torch.nn module in PyTorch is a core library that provides a wide array of classes & functions designed to help developers build neural networks efficiently and effectively. It abstracts the complexity of creating and training neural networks by offering pre built layers, loss functions, activation functions, etc; enabling you to focus on designing and exprementing with model architecture."],"metadata":{"id":"vX97a1Opko48"}},{"cell_type":"code","execution_count":17,"metadata":{"id":"0Pkfjw8Ejuvb","executionInfo":{"status":"ok","timestamp":1735884004995,"user_tz":-330,"elapsed":365,"user":{"displayName":"Brave","userId":"11174309924618507612"}}},"outputs":[],"source":[" #Import libraries and Define model class for Single Neural Network\n","import torch\n","import torch.nn as nn"]},{"cell_type":"markdown","source":["### Importing Libraries and Defining the Model Class\n","\n","This cell imports necessary libraries and defines the architecture of a single-layer neural network using PyTorch's `nn.Module`.\n","\n","**Concepts:**\n","\n","* **torch.nn:** PyTorch's neural network module containing building blocks for creating neural networks.\n","* **nn.Module:** Base class for all neural network modules in PyTorch.\n","* **nn.Linear:** Applies a linear transformation to the incoming data.\n","* **nn.Sigmoid:** Applies the sigmoid activation function.\n","* **__init__:** Constructor of the class, where layers and components are initialized.\n","* **forward:** Defines the forward pass of the model, specifying how data flows through the network."],"metadata":{"id":"nr-tdCuX0Gfp"}},{"cell_type":"code","source":["class Model(nn.Module):\n","  def __init__(self,no_features):\n","    super().__init__()\n","    self.linear = nn.Linear(no_features,1)\n","    self.sigmoid = nn.Sigmoid()\n","\n","  def forward(self,features):\n","    out = self.linear(features)\n","    out = self.sigmoid(out)\n","\n","    return out"],"metadata":{"id":"v-plPRzguktK","executionInfo":{"status":"ok","timestamp":1735884006219,"user_tz":-330,"elapsed":4,"user":{"displayName":"Brave","userId":"11174309924618507612"}}},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":["### Creating a Fake Dataset and Model Instance\n","\n","This cell creates a fake dataset using `torch.rand` and instantiates the `Model` class defined earlier.\n","\n","**Concepts:**\n","\n","* **torch.rand:** Generates a tensor with random numbers drawn from a uniform distribution.\n","* **Model(features.shape[1]):** Creates an instance of the `Model` class, passing the number of input features.\n","* **model(features):** Calls the `forward` method of the model to perform a forward pass."],"metadata":{"id":"dvzV_Bka0Z2w"}},{"cell_type":"code","source":["#Creating a fake dataset\n","features = torch.rand(20,5)\n","\n","#Creating instance of the model\n","model = Model(features.shape[1])\n","\n","#Calling the model for forward pass\n","#model.forward(features)\n","model(features)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eqDAkmbjruFy","executionInfo":{"status":"ok","timestamp":1735884007520,"user_tz":-330,"elapsed":8,"user":{"displayName":"Brave","userId":"11174309924618507612"}},"outputId":"364353ea-72b5-42f4-e14d-73534d5a673d"},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.4574],\n","        [0.4296],\n","        [0.4859],\n","        [0.4202],\n","        [0.3494],\n","        [0.3462],\n","        [0.3848],\n","        [0.4676],\n","        [0.4338],\n","        [0.4036],\n","        [0.3621],\n","        [0.4599],\n","        [0.4448],\n","        [0.4890],\n","        [0.4537],\n","        [0.4257],\n","        [0.4453],\n","        [0.4309],\n","        [0.3635],\n","        [0.3833]], grad_fn=<SigmoidBackward0>)"]},"metadata":{},"execution_count":19}]},{"cell_type":"markdown","source":["### Accessing Model Weights\n","\n","This cell shows how to access the weights of the linear layer in the model.\n","\n","**Concepts:**\n","\n","* **model.linear.weight:** Accesses the weight tensor of the linear layer."],"metadata":{"id":"OMqmvKzP0hnR"}},{"cell_type":"code","source":["#Showing model weights\n","model.linear.weight"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ms1aYxyRtM8o","executionInfo":{"status":"ok","timestamp":1735884009068,"user_tz":-330,"elapsed":5,"user":{"displayName":"Brave","userId":"11174309924618507612"}},"outputId":"32ba1218-a8ff-46ed-81cb-4644c5bbf2f1"},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Parameter containing:\n","tensor([[-0.4464, -0.4231,  0.3632,  0.1764,  0.2544]], requires_grad=True)"]},"metadata":{},"execution_count":20}]},{"cell_type":"markdown","source":["### Accessing Model Bias\n","\n","This cell shows how to access the bias of the linear layer in the model.\n","\n","**Concepts:**\n","\n","* **model.linear.bias:** Accesses the bias tensor of the linear layer."],"metadata":{"id":"vsJaJm9U0oCe"}},{"cell_type":"code","source":["#Showing model bias\n","model.linear.bias"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ujuma0XgtjZH","executionInfo":{"status":"ok","timestamp":1735884011076,"user_tz":-330,"elapsed":348,"user":{"displayName":"Brave","userId":"11174309924618507612"}},"outputId":"d33e7de5-11f2-4532-fa8d-d7e64f4ebfc3"},"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Parameter containing:\n","tensor([-0.2947], requires_grad=True)"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["!pip install torchinfo"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_shDElG1t4FY","executionInfo":{"status":"ok","timestamp":1735884016830,"user_tz":-330,"elapsed":4664,"user":{"displayName":"Brave","userId":"11174309924618507612"}},"outputId":"179288a8-66e2-42cd-f8c9-505d69d689b1"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torchinfo in /usr/local/lib/python3.10/dist-packages (1.8.0)\n"]}]},{"cell_type":"markdown","source":["### Model Summary using torchinfo\n","\n","This cell uses the `summary` function from the `torchinfo` library to print a summary of the model architecture. The input size is specified as (1, 5), which indicates the dimensions of the input to the model.\n","\n","**Concepts:**\n","\n","* `from torchinfo import summary`: Imports the `summary` function from the `torchinfo` library.\n","* `summary(model, input_size=(1, 5))`:  Calls the summary function, providing the model and the size of the input tensor as arguments.\n","\n","\n","* **torchinfo:**  A library to provide information about PyTorch models, such as the number of parameters, the size of the input and output tensors, and the computational cost.\n","\n","**Note:** Make sure to install `torchinfo` library before trying to summarize the model in subsequent cells."],"metadata":{"id":"dCZXmpuL0t2A"}},{"cell_type":"code","source":["from torchinfo import summary\n","\n","summary(model,input_size=(1,5))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jp39wR4nuETP","executionInfo":{"status":"ok","timestamp":1735884018159,"user_tz":-330,"elapsed":5,"user":{"displayName":"Brave","userId":"11174309924618507612"}},"outputId":"87f40fbe-8bbe-49ac-e79d-4a6378aabcf1"},"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["==========================================================================================\n","Layer (type:depth-idx)                   Output Shape              Param #\n","==========================================================================================\n","Model                                    [1, 1]                    --\n","├─Linear: 1-1                            [1, 1]                    6\n","├─Sigmoid: 1-2                           [1, 1]                    --\n","==========================================================================================\n","Total params: 6\n","Trainable params: 6\n","Non-trainable params: 0\n","Total mult-adds (M): 0.00\n","==========================================================================================\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 0.00\n","Params size (MB): 0.00\n","Estimated Total Size (MB): 0.00\n","=========================================================================================="]},"metadata":{},"execution_count":23}]},{"cell_type":"markdown","source":["### Creating a Multilayer Neural Network Model\n","\n","This cell defines a more complex neural network with multiple layers using PyTorch's `nn.Module`. This model introduces a hidden layer with a ReLU activation function, demonstrating a typical structure for multilayer perceptrons (MLPs).\n","\n","**Concepts:**\n","\n","* **Multilayer Perceptron (MLP):** A type of feedforward neural network consisting of multiple layers of interconnected nodes (neurons).\n","* **Hidden Layer:** A layer between the input and output layers that processes the input data and extracts features.\n","* **nn.ReLU:** Applies the Rectified Linear Unit (ReLU) activation function, introducing non-linearity to the model.\n","* **Multiple Linear Layers:** The model uses two linear layers (`nn.Linear`) for transforming the data at different stages."],"metadata":{"id":"IaXS9OQcupZS"}},{"cell_type":"code","source":["class Model1(nn.Module):\n","  def __init__(self,no_features):\n","    super().__init__()\n","    self.linear1 = nn.Linear(no_features,3)\n","    self.relu = nn.ReLU()\n","    self.linear2 = nn.Linear(3,1)\n","    self.sigmoid = nn.Sigmoid()\n","\n","  def forward(self,features):\n","    out = self.linear1(features)\n","    out = self.relu(out)\n","    out = self.linear2(out)\n","    out = self.sigmoid(out)\n","\n","    return out"],"metadata":{"id":"7k92T_6-uPro","executionInfo":{"status":"ok","timestamp":1735884174005,"user_tz":-330,"elapsed":752,"user":{"displayName":"Brave","userId":"11174309924618507612"}}},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":["### Instantiating and Using the Multilayer Model\n","\n","This cell creates a fake dataset and an instance of the `Model1` class (the multilayer model defined in the previous cell). It then performs a forward pass using the fake data.\n","\n","**Concepts:**\n","\n","* **Model Instantiation:** Creates an instance of the `Model1` class, passing the number of input features.\n","* **Forward Pass:** Calls the `forward` method of the model to process the input data and obtain the output."],"metadata":{"id":"TQs9ZfXv1Sys"}},{"cell_type":"code","source":["features = torch.rand(15,5)\n","model1 = Model1(features.shape[1])\n","model1(features)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0RO07tsTvNIE","executionInfo":{"status":"ok","timestamp":1735884174422,"user_tz":-330,"elapsed":6,"user":{"displayName":"Brave","userId":"11174309924618507612"}},"outputId":"694bfb03-a1f3-42eb-a17f-b428c171e41c"},"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.4762],\n","        [0.5015],\n","        [0.4655],\n","        [0.5249],\n","        [0.4854],\n","        [0.5118],\n","        [0.4889],\n","        [0.5081],\n","        [0.5352],\n","        [0.4552],\n","        [0.4948],\n","        [0.4931],\n","        [0.4986],\n","        [0.4831],\n","        [0.5338]], grad_fn=<SigmoidBackward0>)"]},"metadata":{},"execution_count":29}]},{"cell_type":"markdown","source":["### Accessing Weights and Biases of Multilayer Model\n","\n","These cells demonstrate how to access the weights and biases of the individual layers in the multilayer model.\n","\n","**Concepts:**\n","\n","* **Layer-Specific Access:** The code shows how to access the weights and biases of specific layers by their names (e.g., `model1.linear1.weight`).\n","* **Weights and Biases:** These are the learnable parameters of the neural network that are adjusted during training."],"metadata":{"id":"PYkOY93i1X0m"}},{"cell_type":"code","source":["model1.linear1.weight"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mcz31cLbvjC2","executionInfo":{"status":"ok","timestamp":1735884243859,"user_tz":-330,"elapsed":361,"user":{"displayName":"Brave","userId":"11174309924618507612"}},"outputId":"12a71465-bcb6-40a9-e044-f049c7783cdf"},"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Parameter containing:\n","tensor([[-0.2616, -0.3352,  0.3205, -0.0973,  0.3944],\n","        [-0.4082, -0.2371, -0.0666, -0.0053,  0.3661],\n","        [ 0.3004, -0.2962, -0.3246, -0.4261, -0.4268]], requires_grad=True)"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":["model1.linear2.weight"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-ap9eK4XwvhZ","executionInfo":{"status":"ok","timestamp":1735884256656,"user_tz":-330,"elapsed":365,"user":{"displayName":"Brave","userId":"11174309924618507612"}},"outputId":"3919aeb9-e591-4594-fe21-0d425914cbd9"},"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Parameter containing:\n","tensor([[-0.5359, -0.2030,  0.0487]], requires_grad=True)"]},"metadata":{},"execution_count":34}]},{"cell_type":"code","source":["model1.linear1.bias"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gPpCsjqYw7CW","executionInfo":{"status":"ok","timestamp":1735884269651,"user_tz":-330,"elapsed":717,"user":{"displayName":"Brave","userId":"11174309924618507612"}},"outputId":"1c9ab69e-0184-41fa-ea99-6d703e4e38c7"},"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Parameter containing:\n","tensor([0.1821, 0.3284, 0.4057], requires_grad=True)"]},"metadata":{},"execution_count":35}]},{"cell_type":"code","source":["model1.linear2.bias"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9yuslCnrw-ML","executionInfo":{"status":"ok","timestamp":1735884280866,"user_tz":-330,"elapsed":343,"user":{"displayName":"Brave","userId":"11174309924618507612"}},"outputId":"ad405047-86c8-4ca8-a81e-60c4f6f20427"},"execution_count":36,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Parameter containing:\n","tensor([0.1410], requires_grad=True)"]},"metadata":{},"execution_count":36}]},{"cell_type":"markdown","source":["### Model Summary for Multilayer Model\n","\n","This cell uses the `summary` function from the `torchinfo` library to display a summary of the architecture of the multilayer model, including layer details, parameters, and input/output shapes.\n","\n","**Concepts:**\n","\n","* **Model Summary:** Provides a concise overview of the model's structure."],"metadata":{"id":"J5bHwMnY1dfb"}},{"cell_type":"code","source":["summary(model1,input_size=(1,5))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MIT9S11HxA-v","executionInfo":{"status":"ok","timestamp":1735884322422,"user_tz":-330,"elapsed":409,"user":{"displayName":"Brave","userId":"11174309924618507612"}},"outputId":"bfd584a0-aa76-48c3-da7c-f1ac6eec0b6b"},"execution_count":38,"outputs":[{"output_type":"execute_result","data":{"text/plain":["==========================================================================================\n","Layer (type:depth-idx)                   Output Shape              Param #\n","==========================================================================================\n","Model1                                   [1, 1]                    --\n","├─Linear: 1-1                            [1, 3]                    18\n","├─ReLU: 1-2                              [1, 3]                    --\n","├─Linear: 1-3                            [1, 1]                    4\n","├─Sigmoid: 1-4                           [1, 1]                    --\n","==========================================================================================\n","Total params: 22\n","Trainable params: 22\n","Non-trainable params: 0\n","Total mult-adds (M): 0.00\n","==========================================================================================\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 0.00\n","Params size (MB): 0.00\n","Estimated Total Size (MB): 0.00\n","=========================================================================================="]},"metadata":{},"execution_count":38}]},{"cell_type":"markdown","source":["### Creating a Multilayer Model using Sequential Container\n","\n","This cell introduces an alternative way to define a multilayer neural network using PyTorch's `nn.Sequential` container. This approach simplifies the model definition by sequentially stacking layers.\n","\n","**Concepts:**\n","\n","* **nn.Sequential:** A container that allows you to define a sequential arrangement of layers.\n","* **Simplified Model Definition:** `nn.Sequential` makes it easier to create and manage models with multiple layers.\n","\n","\n","**Containers in PyTorch**\n","\n","In PyTorch, containers are objects that hold and organize other modules (When there are multiple layers to reduce the complexity we use containers). They provide a way to structure your neural networks and manage their components efficiently. There are several types of containers available in PyTorch:\n","\n","1. **`nn.Sequential`:** This container is designed to hold a sequence of modules, where the output of one module becomes the input to the next. It is commonly used for building simple feedforward networks.\n","\n","2. **`nn.ModuleList`:** This container acts like a Python list to store a collection of modules. It allows you to iterate over the modules or access them by index. However, it does not automatically define a forward pass like `nn.Sequential`.\n","\n","3. **`nn.ModuleDict`:** Similar to `nn.ModuleList`, but it uses a dictionary-like interface to store modules, allowing you to access them by name. It also does not define a forward pass.\n","\n","\n","**Why use `nn.Sequential`?**\n","\n","The `nn.Sequential` container is preferred in this case because it offers a concise and straightforward way to define a linear sequence of operations, which is typical for many feedforward neural networks. It automatically handles the connections between layers and defines the forward pass, making the code more readable and easier to manage."],"metadata":{"id":"Iwdi2FVZxfS4"}},{"cell_type":"code","source":["class Model3(nn.Module):\n","  def __init__(self,no_features):\n","    super().__init__()\n","    self.network = nn.Sequential(\n","        nn.Linear(no_features,3),\n","        nn.ReLU(),\n","        nn.Linear(3,1),\n","        nn.Sigmoid()\n","    )\n","\n","  def forward(self,features):\n","    out = self.network(features)\n","\n","    return out"],"metadata":{"id":"mTZU2_PHxJdF","executionInfo":{"status":"ok","timestamp":1735884726809,"user_tz":-330,"elapsed":360,"user":{"displayName":"Brave","userId":"11174309924618507612"}}},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":["### Instantiating and Using the Sequential Model\n","\n","This cell creates a fake dataset and an instance of the `Model3` class (the model defined using `nn.Sequential`). It then performs a forward pass.\n","\n","**Concepts:**\n","\n","* **Model Instantiation:** Creates an instance of the `Model3` class, passing the number of input features.\n","* **Forward Pass:** Calls the `forward` method to process the input data."],"metadata":{"id":"J9otBxSX2FwT"}},{"cell_type":"code","source":["features = torch.rand(10,5)\n","model3 = Model3(features.shape[1])\n","model3(features)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZJSwrJRmyZob","executionInfo":{"status":"ok","timestamp":1735884728366,"user_tz":-330,"elapsed":10,"user":{"displayName":"Brave","userId":"11174309924618507612"}},"outputId":"ac4c71b0-936d-4b35-d8f6-b9296ceae837"},"execution_count":43,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.5894],\n","        [0.5894],\n","        [0.5894],\n","        [0.5894],\n","        [0.5894],\n","        [0.5894],\n","        [0.5894],\n","        [0.5894],\n","        [0.5936],\n","        [0.5894]], grad_fn=<SigmoidBackward0>)"]},"metadata":{},"execution_count":43}]},{"cell_type":"code","source":[],"metadata":{"id":"GHjCaN3VyjZQ"},"execution_count":null,"outputs":[]}]}